{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count        78514\n",
      "unique       78460\n",
      "top       a6807000\n",
      "freq             3\n",
      "Name: addr, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a6000000', 'a6003000', 'a6004000', 'a6005000', 'a6006000']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from itertools import islice\n",
    "\n",
    "max_rows = 2000\n",
    "data = []\n",
    "df = pd.read_csv('./data/raw/fltrace_out/fluidanimate/500_300/fltrace-data-faults-26866-1.out', nrows=max_rows, index_col=1)\n",
    "data = df['addr'].values.tolist()\n",
    "# print(df.columns)\n",
    "# print(df['addr'].describe())\n",
    "# print(df.head())\n",
    "split_index = int(len(data) * 0.8)\n",
    "train_data = data[:split_index]\n",
    "validation_data = data[split_index:]\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAccessDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, sequence_length=10):\n",
    "        self.input_ids = []\n",
    "        self.label_ids = []\n",
    "        self.attention_masks = []\n",
    "        sequences = \"\"\n",
    "        label_sequences = \"\"\n",
    "\n",
    "        for index in range(len(data) - 1):\n",
    "            sequences += f\"{data[index]}   \"\n",
    "            label_sequences += f\"{data[index + 1]}   \"\n",
    "\n",
    "            if (index + 1) % sequence_length == 0 or (index + 1) == len(data) - 1:\n",
    "                # print(sequences)\n",
    "                # print(label_sequences)\n",
    "\n",
    "                encoding_in = tokenizer(sequences, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\", return_attention_mask=True)\n",
    "                encoding_label = tokenizer(label_sequences, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\", return_attention_mask=True)\n",
    "\n",
    "                self.input_ids.append(encoding_in['input_ids'])\n",
    "                self.label_ids.append(encoding_label['input_ids'])\n",
    "                self.attention_masks.append(encoding_in['attention_mask'])\n",
    "\n",
    "                sequences = \"\"\n",
    "                label_sequences = \"\"\n",
    "\n",
    "\n",
    "        if sequences:\n",
    "\n",
    "            encoding_in = tokenizer(sequences, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\", return_attention_mask=True)\n",
    "            encoding_label = tokenizer(label_sequences, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\", return_attention_mask=True)\n",
    "            \n",
    "            self.input_ids.append(encoding_in['input_ids'])\n",
    "            self.label_ids.append(encoding_label['input_ids'])\n",
    "            self.attention_masks.append(encoding_in['attention_mask'])\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx].squeeze(), self.attention_masks[idx].squeeze(), self.label_ids[idx].squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "epoch  1\n",
      "epoch  2\n",
      "epoch  3\n",
      "epoch  4\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "   tokenizer.add_special_tokens({'pad_token': '[PAD]'})# \n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.dropout = 0.1\n",
    "model.config.attention_dropout = 0.1\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = MemoryAccessDataset(tokenizer, train_data)\n",
    "validation_dataset = MemoryAccessDataset(tokenizer, validation_data)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=2)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):  # Define epochs\n",
    "    print(\"epoch \", epoch)\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        inputs, masks, labels = batch\n",
    "        inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_page_address(model, tokenizer, prompt):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)  # Ensure the model is on the correct device\n",
    "    \n",
    "    # Create the prompt from the input \n",
    "    \n",
    "    # Encode the prompt to be suitable for the model\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", return_attention_mask=True).to(device)\n",
    "    # print(inputs)\n",
    "    # print(\"prompt :\" + prompt)\n",
    "\n",
    "    # Generate the output using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length = 16,\n",
    "            min_length = 16,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id   \n",
    "        )\n",
    "\n",
    "    \n",
    "    # Decode the generated output to text\n",
    "    predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # print(\"Generated text: \" + predicted_text)\n",
    "    # Extract the next page address from the predicted text\n",
    "    predicted_page_address = predicted_text.split()[-1] \n",
    "    truncated_predicted_text = predicted_page_address[:8]\n",
    "\n",
    "    final_address = hex(int(truncated_predicted_text, 16) + 0x1000)\n",
    "    clean_hex = final_address.replace('0x', '')\n",
    "\n",
    "    return clean_hex\n",
    "\n",
    "# # Example usage\n",
    "# page_address = \"-77547\"  # Example current page address\n",
    "# predicted_page_address = predict_next_page_address(model, tokenizer, page_address)\n",
    "# print(f\"Predicted Next Page Address: {predicted_page_address}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: a701c000  Actual: a701c000\n",
      "Predicted: a701d000  Actual: a701d000\n",
      "Predicted: a701e000  Actual: a701e000\n",
      "Predicted: a701f000  Actual: a701f000\n",
      "Predicted: a7020000  Actual: a7020000\n",
      "Predicted: a7021000  Actual: a7021000\n",
      "Predicted: a7022000  Actual: a7022000\n",
      "Predicted: a7023000  Actual: a7023000\n",
      "Predicted: a7024000  Actual: a7024000\n",
      "Predicted: a7025000  Actual: a7025000\n",
      "Predicted: a7026000  Actual: a7026000\n",
      "Predicted: a7027000  Actual: a7027000\n",
      "Predicted: a7028000  Actual: a7028000\n",
      "Predicted: a7029000  Actual: a7029000\n",
      "Predicted: a702a000  Actual: a702a000\n",
      "Predicted: a702b000  Actual: a702b000\n",
      "Predicted: a702c000  Actual: a702c000\n",
      "Predicted: a702d000  Actual: a702d000\n",
      "Predicted: a702e000  Actual: a702e000\n",
      "Predicted: a702f000  Actual: a702f000\n",
      "Predicted: a7030000  Actual: a7030000\n",
      "Predicted: a7031000  Actual: a7031000\n",
      "Predicted: a7032000  Actual: a7032000\n",
      "Predicted: a7033000  Actual: a7033000\n",
      "Predicted: a7034000  Actual: a7034000\n",
      "Predicted: a7035000  Actual: a7035000\n",
      "Predicted: a7036000  Actual: a7036000\n",
      "Predicted: a7037000  Actual: a7037000\n",
      "Predicted: a7038000  Actual: a7038000\n",
      "Predicted: a7039000  Actual: a7039000\n",
      "Predicted: a703a000  Actual: a703a000\n",
      "Predicted: a703b000  Actual: a703b000\n",
      "Predicted: a703c000  Actual: a703c000\n",
      "Predicted: a703d000  Actual: a703d000\n",
      "Predicted: a703e000  Actual: a703e000\n",
      "Predicted: a703f000  Actual: a703f000\n",
      "Predicted: a7040000  Actual: a7040000\n",
      "Predicted: a7041000  Actual: a7041000\n",
      "Predicted: a7042000  Actual: a7042000\n",
      "Predicted: a7043000  Actual: a7043000\n",
      "Predicted: a7044000  Actual: a7044000\n",
      "Predicted: a7045000  Actual: a7045000\n",
      "Predicted: a7046000  Actual: a7046000\n",
      "Predicted: a7047000  Actual: a7047000\n",
      "Predicted: a7048000  Actual: a7048000\n",
      "Predicted: a7049000  Actual: a7049000\n",
      "Predicted: a704a000  Actual: a704a000\n",
      "Predicted: a704b000  Actual: a704b000\n",
      "Predicted: a704c000  Actual: a704c000\n",
      "Predicted: a704d000  Actual: a704d000\n",
      "Predicted: a704e000  Actual: a704e000\n",
      "Predicted: a704f000  Actual: a704f000\n",
      "Predicted: a7050000  Actual: a7050000\n",
      "Predicted: a7051000  Actual: a7051000\n",
      "Predicted: a7052000  Actual: a7052000\n",
      "Predicted: a7053000  Actual: a7053000\n",
      "Predicted: a7054000  Actual: a7054000\n",
      "Predicted: a7055000  Actual: a7055000\n",
      "Predicted: a7056000  Actual: a7056000\n",
      "Predicted: a7057000  Actual: a7057000\n",
      "Predicted: a7058000  Actual: a7058000\n",
      "Predicted: a7059000  Actual: a7059000\n",
      "Predicted: a705a000  Actual: a705a000\n",
      "Predicted: a705b000  Actual: a705b000\n",
      "Predicted: a705c000  Actual: a705c000\n",
      "Predicted: a705d000  Actual: a705d000\n",
      "Predicted: a705e000  Actual: a705e000\n",
      "Predicted: a705f000  Actual: a705f000\n",
      "Predicted: a7060000  Actual: a7060000\n",
      "Predicted: a7061000  Actual: a7061000\n",
      "Predicted: a7062000  Actual: a7062000\n",
      "Predicted: a7063000  Actual: a7063000\n",
      "Predicted: a7064000  Actual: a7064000\n",
      "Predicted: a7065000  Actual: a7065000\n",
      "Predicted: a7066000  Actual: a7066000\n",
      "Predicted: a7067000  Actual: a7067000\n",
      "Predicted: a7068000  Actual: a7068000\n",
      "Predicted: a7069000  Actual: a7069000\n",
      "Predicted: a706a000  Actual: a706a000\n",
      "Predicted: a706b000  Actual: a706b000\n",
      "Predicted: a706c000  Actual: a706c000\n",
      "Predicted: a706d000  Actual: a706d000\n",
      "Predicted: a706e000  Actual: a706e000\n",
      "Predicted: a706f000  Actual: a706f000\n",
      "Predicted: a7070000  Actual: a7070000\n",
      "Predicted: a7071000  Actual: a7071000\n",
      "Predicted: a7072000  Actual: a7072000\n",
      "Predicted: a7073000  Actual: a7073000\n",
      "Predicted: a7074000  Actual: a7074000\n",
      "Predicted: a7075000  Actual: a7075000\n",
      "Predicted: a7076000  Actual: a7076000\n",
      "Predicted: a7077000  Actual: a7077000\n",
      "Predicted: a7078000  Actual: a7078000\n",
      "Predicted: a7079000  Actual: a7079000\n",
      "Predicted: a707a000  Actual: a707a000\n",
      "Predicted: a707b000  Actual: a707b000\n",
      "Predicted: a707c000  Actual: a707c000\n",
      "Predicted: a707d000  Actual: a707d000\n",
      "Predicted: a707e000  Actual: a707e000\n",
      "Predicted: a707f000  Actual: a707f000\n",
      "Predicted: a7080000  Actual: a7080000\n",
      "Predicted: a7081000  Actual: a7081000\n",
      "Predicted: a7082000  Actual: a7082000\n",
      "Predicted: a7083000  Actual: a7083000\n",
      "Predicted: a7084000  Actual: a7084000\n",
      "Predicted: a7085000  Actual: a7085000\n",
      "Predicted: a7086000  Actual: a7086000\n",
      "Predicted: a7087000  Actual: a7087000\n",
      "Predicted: a7088000  Actual: a7088000\n",
      "Predicted: a7089000  Actual: a7089000\n",
      "Predicted: a708a000  Actual: a708a000\n",
      "Predicted: a708b000  Actual: a708b000\n",
      "Predicted: a708c000  Actual: a708c000\n",
      "Predicted: a708d000  Actual: a708d000\n",
      "Predicted: a708e000  Actual: a708e000\n",
      "Predicted: a708f000  Actual: a708f000\n",
      "Predicted: a7090000  Actual: a7090000\n",
      "Predicted: a7091000  Actual: a7091000\n",
      "Predicted: a7092000  Actual: a7092000\n",
      "Predicted: a7093000  Actual: a7093000\n",
      "Predicted: a7094000  Actual: a7094000\n",
      "Predicted: a7095000  Actual: a7095000\n",
      "Predicted: a7096000  Actual: a7096000\n",
      "Predicted: a7097000  Actual: a7097000\n",
      "Predicted: a7098000  Actual: a7098000\n",
      "Predicted: a7099000  Actual: a7099000\n",
      "Predicted: a709a000  Actual: a709a000\n",
      "Predicted: a709b000  Actual: a709b000\n",
      "Predicted: a709c000  Actual: a709c000\n",
      "Predicted: a709d000  Actual: a709d000\n",
      "Predicted: a709e000  Actual: a709e000\n",
      "Predicted: a709f000  Actual: a709f000\n",
      "Predicted: a70a0000  Actual: a70a0000\n",
      "Predicted: a70a1000  Actual: a70a1000\n",
      "Predicted: a70a2000  Actual: a70a2000\n",
      "Predicted: a70a3000  Actual: a70a3000\n",
      "Predicted: a70a4000  Actual: a70a4000\n",
      "Predicted: a70a5000  Actual: a70a5000\n",
      "Predicted: a70a6000  Actual: a70a6000\n",
      "Predicted: a70a7000  Actual: a70a7000\n",
      "Predicted: a70a8000  Actual: a70a8000\n",
      "Predicted: a70a9000  Actual: a70a9000\n",
      "Predicted: a70aa000  Actual: a70aa000\n",
      "Predicted: a70ab000  Actual: a70ab000\n",
      "Predicted: a70ac000  Actual: a70ac000\n",
      "Predicted: a70ad000  Actual: a70ad000\n",
      "Predicted: a70ae000  Actual: a70ae000\n",
      "Predicted: a70af000  Actual: a70af000\n",
      "Predicted: a70b0000  Actual: a70b0000\n",
      "Predicted: a70b1000  Actual: a70b1000\n",
      "Predicted: a70b2000  Actual: a70b2000\n",
      "Predicted: a70b3000  Actual: a70b3000\n",
      "Predicted: a70b4000  Actual: a70b4000\n",
      "Predicted: a70b5000  Actual: a70b5000\n",
      "Predicted: a70b6000  Actual: a70b6000\n",
      "Predicted: a70b7000  Actual: a70b7000\n",
      "Predicted: a70b8000  Actual: a70b8000\n",
      "Predicted: a70b9000  Actual: a70b9000\n",
      "Predicted: a70ba000  Actual: a70ba000\n",
      "Predicted: a70bb000  Actual: a70bb000\n",
      "Predicted: a70bc000  Actual: a70bc000\n",
      "Predicted: a70bd000  Actual: a70bd000\n",
      "Predicted: a70be000  Actual: a70be000\n",
      "Predicted: a70bf000  Actual: a70bf000\n",
      "Predicted: a70c0000  Actual: a70c0000\n",
      "Predicted: a70c1000  Actual: a70c1000\n",
      "Predicted: a70c2000  Actual: a70c2000\n",
      "Predicted: a70c3000  Actual: a70c3000\n",
      "Predicted: a70c4000  Actual: a70c4000\n",
      "Predicted: a70c5000  Actual: a70c5000\n",
      "Predicted: a70c6000  Actual: a70c6000\n",
      "Predicted: a70c7000  Actual: a70c7000\n",
      "Predicted: a70c8000  Actual: a70c8000\n",
      "Predicted: a70c9000  Actual: a70c9000\n",
      "Predicted: a70ca000  Actual: a70ca000\n",
      "Predicted: a70cb000  Actual: a70cb000\n",
      "Predicted: a70cc000  Actual: a70cc000\n",
      "Predicted: a70cd000  Actual: a70cd000\n",
      "Predicted: a70ce000  Actual: a70ce000\n",
      "Predicted: a70cf000  Actual: a70cf000\n",
      "Predicted: a70d0000  Actual: a70d0000\n",
      "Predicted: a70d1000  Actual: a70d1000\n",
      "Predicted: a70d2000  Actual: a70d2000\n",
      "Predicted: a70d3000  Actual: a70d3000\n",
      "Predicted: a70d4000  Actual: a70d4000\n",
      "Predicted: a70d5000  Actual: a70d5000\n",
      "Predicted: a70d6000  Actual: a70d6000\n",
      "Predicted: a70d7000  Actual: a70d7000\n",
      "Predicted: a70d8000  Actual: a70d8000\n",
      "Predicted: a70d9000  Actual: a70d9000\n",
      "Predicted: a70da000  Actual: a70da000\n",
      "Predicted: a70db000  Actual: a70db000\n",
      "Predicted: a70dc000  Actual: a70dc000\n",
      "Predicted: a70dd000  Actual: a70dd000\n",
      "Predicted: a70de000  Actual: a70de000\n",
      "Predicted: a70df000  Actual: a70df000\n",
      "Predicted: a70e0000  Actual: a70e0000\n",
      "Predicted: a70e1000  Actual: a70e1000\n",
      "Predicted: a70e2000  Actual: a70e2000\n",
      "Predicted: a70e3000  Actual: a70e3000\n",
      "Predicted: a70e4000  Actual: a70e4000\n",
      "Predicted: a70e5000  Actual: a70e5000\n",
      "Predicted: a70e6000  Actual: a70e6000\n",
      "Predicted: a70e7000  Actual: a70e7000\n",
      "Predicted: a70e8000  Actual: a70e8000\n",
      "Predicted: a70e9000  Actual: a70e9000\n",
      "Predicted: a70ea000  Actual: a70ea000\n",
      "Predicted: a70eb000  Actual: a70eb000\n",
      "Predicted: a70ec000  Actual: a70ec000\n",
      "Predicted: a70ed000  Actual: a70ed000\n",
      "Predicted: a70ee000  Actual: a70ee000\n",
      "Predicted: a70ef000  Actual: a70ef000\n",
      "Predicted: a70f0000  Actual: a70f0000\n",
      "Predicted: a70f1000  Actual: a70f1000\n",
      "Predicted: a70f2000  Actual: a70f2000\n",
      "Predicted: a70f3000  Actual: a70f3000\n",
      "Predicted: a70f4000  Actual: a70f4000\n",
      "Predicted: a70f5000  Actual: a70f5000\n",
      "Predicted: a70f6000  Actual: a70f6000\n",
      "Predicted: a70f7000  Actual: a70f7000\n",
      "Predicted: a70f8000  Actual: a70f8000\n",
      "Predicted: a70f9000  Actual: a70f9000\n",
      "Predicted: a70fa000  Actual: a70fa000\n",
      "Predicted: a70fb000  Actual: a70fb000\n",
      "Predicted: a70fc000  Actual: a70fc000\n",
      "Predicted: a70fd000  Actual: a70fd000\n",
      "Predicted: a70fe000  Actual: a70fe000\n",
      "Predicted: a70ff000  Actual: a70ff000\n",
      "Predicted: a7100000  Actual: a7100000\n",
      "Predicted: a7101000  Actual: a7101000\n",
      "Predicted: a7102000  Actual: a7102000\n",
      "Predicted: a7103000  Actual: a7103000\n",
      "Predicted: a7104000  Actual: a7104000\n",
      "Predicted: a7105000  Actual: a7105000\n",
      "Predicted: a7106000  Actual: a7106000\n",
      "Predicted: a7107000  Actual: a7107000\n",
      "Predicted: a7108000  Actual: a7108000\n",
      "Predicted: a7109000  Actual: a7109000\n",
      "Predicted: a710a000  Actual: a710a000\n",
      "Predicted: a710b000  Actual: a710b000\n",
      "Predicted: a710c000  Actual: a710c000\n",
      "Predicted: a710d000  Actual: a710d000\n",
      "Predicted: a710e000  Actual: a710e000\n",
      "Predicted: a710f000  Actual: a710f000\n",
      "Predicted: a7110000  Actual: a7110000\n",
      "Predicted: a7111000  Actual: a7111000\n",
      "Predicted: a7112000  Actual: a7112000\n",
      "Predicted: a7113000  Actual: a7113000\n",
      "Predicted: a7114000  Actual: a7114000\n",
      "Predicted: a7115000  Actual: a7115000\n",
      "Predicted: a7116000  Actual: a7116000\n",
      "Predicted: a7117000  Actual: a7117000\n",
      "Predicted: a7118000  Actual: a7118000\n",
      "Predicted: a7119000  Actual: a7119000\n",
      "Predicted: a711a000  Actual: a711a000\n",
      "Predicted: a711b000  Actual: a711b000\n",
      "Predicted: a711c000  Actual: a711c000\n",
      "Predicted: a711d000  Actual: a711d000\n",
      "Predicted: a711e000  Actual: a711e000\n",
      "Predicted: a711f000  Actual: a711f000\n",
      "Predicted: a7120000  Actual: a7120000\n",
      "Predicted: a7121000  Actual: a7121000\n",
      "Predicted: a7122000  Actual: a7122000\n",
      "Predicted: a7123000  Actual: a7123000\n",
      "Predicted: a7124000  Actual: a7124000\n",
      "Predicted: a7125000  Actual: a7125000\n",
      "Predicted: a7126000  Actual: a7126000\n",
      "Predicted: a7127000  Actual: a7127000\n",
      "Predicted: a7128000  Actual: a7128000\n",
      "Predicted: a7129000  Actual: a7129000\n",
      "Predicted: a712a000  Actual: a712a000\n",
      "Predicted: a712b000  Actual: a712b000\n",
      "Predicted: a712c000  Actual: a712c000\n",
      "Predicted: a712d000  Actual: a712d000\n",
      "Predicted: a712e000  Actual: a712e000\n",
      "Predicted: a712f000  Actual: a712f000\n",
      "Predicted: a7130000  Actual: a7130000\n",
      "Predicted: a7131000  Actual: a7131000\n",
      "Predicted: a7132000  Actual: a7132000\n",
      "Predicted: a7133000  Actual: a7133000\n",
      "Predicted: a7134000  Actual: a7134000\n",
      "Predicted: a7135000  Actual: a7135000\n",
      "Predicted: a7136000  Actual: a7136000\n",
      "Predicted: a7137000  Actual: a7137000\n",
      "Predicted: a7138000  Actual: a7138000\n",
      "Predicted: a7139000  Actual: a7139000\n",
      "Predicted: a713a000  Actual: a713a000\n",
      "Predicted: a713b000  Actual: a713b000\n",
      "Predicted: a713c000  Actual: a713c000\n",
      "Predicted: a713d000  Actual: a713d000\n",
      "Predicted: a713e000  Actual: a713e000\n",
      "Predicted: a713f000  Actual: a713f000\n",
      "Predicted: a7140000  Actual: a7140000\n",
      "Predicted: a7141000  Actual: a7141000\n",
      "Predicted: a7142000  Actual: a7142000\n",
      "Predicted: a7143000  Actual: a7143000\n",
      "Predicted: a7144000  Actual: a7144000\n",
      "Predicted: a7145000  Actual: a7145000\n",
      "Predicted: a7146000  Actual: a7146000\n",
      "Predicted: a7147000  Actual: a7147000\n",
      "Predicted: a7148000  Actual: a7148000\n",
      "Predicted: a7149000  Actual: a7149000\n",
      "Predicted: a714a000  Actual: a714a000\n",
      "Predicted: a714b000  Actual: a714b000\n",
      "Predicted: a714c000  Actual: a714c000\n",
      "Predicted: a714d000  Actual: a714d000\n",
      "Predicted: a714e000  Actual: a714e000\n",
      "Predicted: a714f000  Actual: a714f000\n",
      "Predicted: a7150000  Actual: a7150000\n",
      "Predicted: a7151000  Actual: a7151000\n",
      "Predicted: a7152000  Actual: a7152000\n",
      "Predicted: a7153000  Actual: a7153000\n",
      "Predicted: a7154000  Actual: a7154000\n",
      "Predicted: a7155000  Actual: a7155000\n",
      "Predicted: a7156000  Actual: a7156000\n",
      "Predicted: a7157000  Actual: a7157000\n",
      "Predicted: a7158000  Actual: a7158000\n",
      "Predicted: a7159000  Actual: a7159000\n",
      "Predicted: a715a000  Actual: a715a000\n",
      "Predicted: a715b000  Actual: a715b000\n",
      "Predicted: a715c000  Actual: a715c000\n",
      "Predicted: a715d000  Actual: a715d000\n",
      "Predicted: a715e000  Actual: a715e000\n",
      "Predicted: a715f000  Actual: a715f000\n",
      "Predicted: a7160000  Actual: a7160000\n",
      "Predicted: a7161000  Actual: a7161000\n",
      "Predicted: a7162000  Actual: a7162000\n",
      "Predicted: a7163000  Actual: a7163000\n",
      "Predicted: a7164000  Actual: a7164000\n",
      "Predicted: a7165000  Actual: a7165000\n",
      "Predicted: a7166000  Actual: a7166000\n",
      "Predicted: a7167000  Actual: a7167000\n",
      "Predicted: a7168000  Actual: a7168000\n",
      "Predicted: a7169000  Actual: a7169000\n",
      "Predicted: a716a000  Actual: a716a000\n",
      "Predicted: a716b000  Actual: a716b000\n",
      "Predicted: a716c000  Actual: a716c000\n",
      "Predicted: a716d000  Actual: a716d000\n",
      "Predicted: a716e000  Actual: a716e000\n",
      "Predicted: a716f000  Actual: a716f000\n",
      "Predicted: a7170000  Actual: a7170000\n",
      "Predicted: a7171000  Actual: a7171000\n",
      "Predicted: a7172000  Actual: a7172000\n",
      "Predicted: a7173000  Actual: a7173000\n",
      "Predicted: a7174000  Actual: a7174000\n",
      "Predicted: a7175000  Actual: a7175000\n",
      "Predicted: a7176000  Actual: a7176000\n",
      "Predicted: a7177000  Actual: a7177000\n",
      "Predicted: a7178000  Actual: a7178000\n",
      "Predicted: a7179000  Actual: a7179000\n",
      "Predicted: a717a000  Actual: a717a000\n",
      "Predicted: a717b000  Actual: a717b000\n",
      "Predicted: a717c000  Actual: a717c000\n",
      "Predicted: a717d000  Actual: a717d000\n",
      "Predicted: a717e000  Actual: a717e000\n",
      "Predicted: a717f000  Actual: a717f000\n",
      "Predicted: a7180000  Actual: a7180000\n",
      "Predicted: a7181000  Actual: a7181000\n",
      "Predicted: a7182000  Actual: a7182000\n",
      "Predicted: a7183000  Actual: a7183000\n",
      "Predicted: a7184000  Actual: a7184000\n",
      "Predicted: a7185000  Actual: a7185000\n",
      "Predicted: a7186000  Actual: a7186000\n",
      "Predicted: a7187000  Actual: a7187000\n",
      "Predicted: a7188000  Actual: a7188000\n",
      "Predicted: a7189000  Actual: a7189000\n",
      "Predicted: a718a000  Actual: a718a000\n",
      "Predicted: a718b000  Actual: a718b000\n",
      "Predicted: a718c000  Actual: a718c000\n",
      "Predicted: a718d000  Actual: a718d000\n",
      "Predicted: a718e000  Actual: a718e000\n",
      "Predicted: a718f000  Actual: a718f000\n",
      "Predicted: a7190000  Actual: a7190000\n",
      "Predicted: a7191000  Actual: a7191000\n",
      "Predicted: a7192000  Actual: a7192000\n",
      "Predicted: a7193000  Actual: a7193000\n",
      "Predicted: a7194000  Actual: a7194000\n",
      "Predicted: a7195000  Actual: a7195000\n",
      "Predicted: a7196000  Actual: a7196000\n",
      "Predicted: a7197000  Actual: a7197000\n",
      "Predicted: a7198000  Actual: a7198000\n",
      "Predicted: a7199000  Actual: a7199000\n",
      "Predicted: a719a000  Actual: a719a000\n",
      "Predicted: a719b000  Actual: a719b000\n",
      "Predicted: a719c000  Actual: a719c000\n",
      "Predicted: a719d000  Actual: a719d000\n",
      "Predicted: a719e000  Actual: a719e000\n",
      "Predicted: a719f000  Actual: a719f000\n",
      "Predicted: a71a0000  Actual: a71a0000\n",
      "Predicted: a71a1000  Actual: a71a1000\n",
      "Predicted: a71a2000  Actual: a71a2000\n",
      "Predicted: a71a3000  Actual: a71a3000\n",
      "Predicted: a71a4000  Actual: a71a4000\n",
      "Predicted: a71a5000  Actual: a71a5000\n",
      "Predicted: a71a6000  Actual: a71a6000\n",
      "Predicted: a71a7000  Actual: a71a7000\n",
      "Predicted: a71a8000  Actual: a71a8000\n",
      "Predicted: a71a9000  Actual: a71a9000\n",
      "Predicted: a71aa000  Actual: a71aa000\n",
      "Accuracy: 100.00%\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(model, tokenizer, data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for index in range(len(data) - 1):\n",
    "        prompt = f\"{data[index]}\"\n",
    "        next_page_address = data[index + 1]\n",
    "\n",
    "        # Generate prediction and immediately handle output\n",
    "        predicted_page_address = predict_next_page_address(model, tokenizer, prompt)\n",
    "        \n",
    "        # Check if the prediction matches the actual address\n",
    "        if predicted_page_address == next_page_address:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "        # Print results immediately after prediction to maintain order\n",
    "        print(f\"Predicted: {predicted_page_address}  Actual: {next_page_address}\")\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "accuracy = test_accuracy(model, tokenizer, validation_data)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# model_path = \"/home/junting/data/gpt2-self\"\n",
    "# model.save_pretrained(model_path)\n",
    "\n",
    "# # Save the tokenizer\n",
    "# tokenizer_path = \"/home/junting/data/gpt2-self\"\n",
    "# tokenizer.save_pretrained(tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# # Load the model\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "# # Ensure the model is in evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # # Example usage\n",
    "# # page_address = \"-77547\"  # Example current page address\n",
    "# # predicted_page_address = predict_next_page_address(model, tokenizer, page_address)\n",
    "# # print(f\"Predicted Next Page Address: {predicted_page_address}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
